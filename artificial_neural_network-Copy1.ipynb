{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2400,
     "status": "ok",
     "timestamp": 1590257449959,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ZaTwK7ojXr2F",
    "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\KUNAL\\Documents\\Deep_Learning\\Churn_Modelling.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2396,
     "status": "ok",
     "timestamp": 1590257449961,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,3:-1]\n",
    "Y=dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1590257449961,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X.iloc[:,3:-1])\n",
    "X.iloc[:,3:-1] = imputer.transform(X.iloc[:,3:-1])\n",
    "# X.iloc[:,3:-1]=imputer.fit_transform(X.iloc[:,3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c34307b988>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See if there exist any null values or not\n",
    "sns.heatmap(X.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X.iloc[:, 2] = le.fit_transform(X.iloc[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2719,
     "status": "ok",
     "timestamp": 1590257450295,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
      "0             619    France       0  42.0     2.0       0.00            1.0   \n",
      "1             608     Spain       0  41.0     1.0   83807.86            1.0   \n",
      "2             502    France       0  42.0     8.0  159660.80            3.0   \n",
      "3             699    France       0  39.0     1.0       0.00            2.0   \n",
      "4             850     Spain       0  43.0     2.0  125510.82            1.0   \n",
      "...           ...       ...     ...   ...     ...        ...            ...   \n",
      "9995          771    France       1  39.0     5.0       0.00            2.0   \n",
      "9996          516    France       1  35.0    10.0   57369.61            1.0   \n",
      "9997          709    France       0  36.0     7.0       0.00            1.0   \n",
      "9998          772   Germany       1  42.0     3.0   75075.31            2.0   \n",
      "9999          792    France       0  28.0     4.0  130142.79            1.0   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0           1.0             1.0        101348.88  \n",
      "1           0.0             1.0        112542.58  \n",
      "2           1.0             0.0        113931.57  \n",
      "3           0.0             0.0         93826.63  \n",
      "4           1.0             1.0         79084.10  \n",
      "...         ...             ...              ...  \n",
      "9995        1.0             0.0         96270.64  \n",
      "9996        1.0             1.0        101699.77  \n",
      "9997        0.0             1.0         42085.58  \n",
      "9998        1.0             0.0         92888.52  \n",
      "9999        1.0             0.0         38190.78  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "# 1-belongs to row 1\n",
    "\n",
    "#Another way:Make dummy variables\n",
    "#onehotencoder = OneHotEncoder(categorical_features = [2])\n",
    "#X = onehotencoder.fit_transform(X).toarray()\n",
    "#X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2713,
     "status": "ok",
     "timestamp": 1590257450296,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0134888e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 1.1254258e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 1.1393157e+05]\n",
      " ...\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 4.2085580e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 9.2888520e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 3.8190780e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "# 0 for spain & france\n",
    "#1 for germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# we do not apply fit so as to avoid info leakage from test set\n",
    "# Fit- computes the mean & st deviation \n",
    "# Transform- uses the previous measures to autoscale the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "# Create a variable ann as the object of Sequential class\n",
    "# Sequential class is taken from models module from keris library (tf calls keras calls models calls Sequential model)\n",
    "ann=tf.keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.Dense(\n",
    "    units,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element\n",
    "-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer,\n",
    "and bias is a bias vector created by the layer (only applicable if use_bias is True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "# add & drop(for overfitting) is a method where keras calls the dense class \n",
    "# the dense class creates the fully connected layer where it automatically add the input layer\n",
    "# inside our Dense class Unit=no. of neurons(in dense fn we only specify how much hidden neuron's needed,activation fn=rectifier for hidden layer & sigmoid for output layer)\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "# add methods add any one neuron to our model units=1 as we need only one neuron to predict the values as 1 or 0\n",
    "# but for multi classification i.e is abc we need three neuron's as there is no relationship order btw these \n",
    "#a-001,b=010,c=001\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# sigmoid gives better prediction's than threshold's fn as it gives the probability that binary outcome is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "# Optimiser performs SGD by adam to update the weights in each iteration's and reduce the loss i.e cost function\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#Binary class:binary_crossentropy , multi class:categorical_crossentropy - loss/probabilistic metrics,regression-mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33685,
     "status": "ok",
     "timestamp": 1590257481284,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8076\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8194\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8241\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8263\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8334\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8385\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8459\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8506\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8593\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8604\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8627\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8622\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8616\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8625\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8625\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8631\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8639\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8639\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8629\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8627\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8619\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8627\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8640\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8637\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8637\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8621\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8626\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8629\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8646\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8622\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8621\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8634\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8634\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8635\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8627\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8640\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8639\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8634\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8635\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8629\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8636\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8633\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8646\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8644\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8648\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 991us/step - loss: 0.3338 - accuracy: 0.8635\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 955us/step - loss: 0.3337 - accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8651\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8644\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8634\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8645\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8625\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8639\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8634\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8635\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8640\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8637\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8635\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 959us/step - loss: 0.3331 - accuracy: 0.8646\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8634\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8648\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8645\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8639\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8651\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8644\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 999us/step - loss: 0.3325 - accuracy: 0.8645\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8645\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8645\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 907us/step - loss: 0.3327 - accuracy: 0.8644\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8646\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8646\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8643\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8646\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8651\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8640\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8654\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8651\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8658\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8646\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.3325 - accuracy: 0.8652\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8646\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fee4734708>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training ann enter 2 para 1. batch_size=32\n",
    "ann.fit(X_train,Y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGRo3eacgDdC"
   },
   "source": [
    "**Homework**\n",
    "\n",
    "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
    "\n",
    "Geography: France\n",
    "\n",
    "Credit Score: 600\n",
    "\n",
    "Gender: Male\n",
    "\n",
    "Age: 40 years old\n",
    "\n",
    "Tenure: 3 years\n",
    "\n",
    "Balance: \\$ 60000\n",
    "\n",
    "Number of Products: 2\n",
    "\n",
    "Does this customer have a credit card? Yes\n",
    "\n",
    "Is this customer an Active Member: Yes\n",
    "\n",
    "Estimated Salary: \\$ 50000\n",
    "\n",
    "So, should we say goodbye to that customer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhU1LTgPg-kH"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33990,
     "status": "ok",
     "timestamp": 1590257481594,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01335871]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) )\n",
    "#0.03 that the customer has the lower probability to leave the bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGjx94g2n7OV"
   },
   "source": [
    "Therefore, our ANN model predicts that this customer stays in the bank!\n",
    "\n",
    "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
    "\n",
    "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33987,
     "status": "ok",
     "timestamp": 1590257481595,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call predict method\n",
    "Y_pred=ann.predict(X_test)\n",
    "Y_pred=(Y_pred>0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'predictions': Y_pred, 'actual': Y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33981,
     "status": "ok",
     "timestamp": 1590257481595,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1522   73]\n",
      " [ 199  206]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cm)\n",
    "accuracy_score(Y_test,Y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True,fmt = \"d\")\n",
    "plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#saving the model architecture in pdf form\n",
    "ann_viz(ann, view=True, filename='Deep_Learning.gv', title='Model Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeRFWFoGrdaL5S3dx5MWmb",
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
